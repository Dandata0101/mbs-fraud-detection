{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Flatenning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncsv_to_parquet_single_file(csv_file_path=csv4_file_path, output_file_path=output_file_path4, chunksize=100000, sample_rows=None, drop_columns=None)\\ncsv_to_parquet_single_file(csv_file_path=csv5_file_path, output_file_path=output_file_path5, chunksize=100000, sample_rows=None, drop_columns=None)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scripts.csvtopaquet import csv_to_parquet_single_file\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "csv4_file_path = os.path.join(current_directory, '01-data', 'FD_creditcard_data.csv')\n",
    "csv4_file_path = os.path.join(current_directory, '01-data', 'FD_02_apl_train.csv')\n",
    "output_file_path4 = os.path.join(current_directory, '01-data', 'FD_creditcard_data.parquet')\n",
    "output_file_path5 = os.path.join(current_directory, '01-data', 'FD_02_apl_train.parquet')\n",
    "\n",
    "'''\n",
    "csv_to_parquet_single_file(csv_file_path=csv4_file_path, output_file_path=output_file_path4, chunksize=100000, sample_rows=None, drop_columns=None)\n",
    "csv_to_parquet_single_file(csv_file_path=csv5_file_path, output_file_path=output_file_path5, chunksize=100000, sample_rows=None, drop_columns=None)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "parquetFile4 = os.path.join(current_directory, '01-data', 'FD_creditcard_data.parquet')\n",
    "parquetFile5 = os.path.join(current_directory, '01-data', 'FD_02_apl_train.parquet')\n",
    "df4 = pd.read_parquet(parquetFile4)\n",
    "df5 = pd.read_parquet(parquetFile5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model comparsions (FD_creditcard_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danramirez/mbs-fraud-detection/fraudenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 99.80%\n",
      "Random Forest Accuracy: 99.93%\n",
      "KNN Accuracy: 99.67%\n",
      "Gaussian Naive Bayes Accuracy: 98.28%\n"
     ]
    }
   ],
   "source": [
    "from scripts.models import logistic_regression_model, train_and_evaluate_decision_tree,train_and_evaluate_random_forest,train_and_evaluate_knn,train_and_evaluate_gaussian_nb\n",
    "_=logistic_regression_model(df4, target_column='Class', drop_columns=['id'], add_constant=True, return_type='Summary')\n",
    "_= train_and_evaluate_decision_tree(df4, 'Class', ['id'],test_size=0.3, random_state=42, return_accuracy_only=True, top_n_features=20)\n",
    "_= train_and_evaluate_random_forest(df4, 'Class', ['id'], test_size=0.3, random_state=42, return_accuracy_only=True, top_n_features=20)\n",
    "_= train_and_evaluate_knn(df4, 'Class', ['id'], n_neighbors=5, return_accuracy_only=True)\n",
    "_= train_and_evaluate_gaussian_nb(df4, 'Class', ['id'], return_accuracy_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights**:\n",
    "- The comparison between different models for the `FD_creditcard_data` dataset shows a clear distinction in model performance, with Random Forest achieving the highest accuracy at 99.93%, followed closely by Decision Tree and KNN models. The Gaussian Naive Bayes model, however, lags behind significantly with an accuracy of 98.28%.\n",
    "- This performance disparity suggests that ensemble methods like Random Forest are more adept at handling the complexities and nuances of the credit card fraud detection dataset, likely due to their ability to model non-linear relationships and interactions between variables more effectively than simpler models like Gaussian Naive Bayes.\n",
    "- The logistic regression details further substantiate the importance of feature selection and the impact of different variables on predicting fraudulent transactions. For instance, the variables with significant p-values (e.g., V14, V19, Amount) indicate a stronger relationship with the outcome (Class), highlighting the necessity for careful feature engineering and selection in improving model accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  Class   No. Observations:                 5050\n",
      "Model:                          Logit   Df Residuals:                     5020\n",
      "Method:                           MLE   Df Model:                           29\n",
      "Date:                Sun, 31 Mar 2024   Pseudo R-squ.:                  0.8852\n",
      "Time:                        15:14:52   Log-Likelihood:                -32.196\n",
      "converged:                       True   LL-Null:                       -280.51\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.421e-86\n",
      "=================================================================================\n",
      "                    coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "const           -10.4734      2.538     -4.127      0.000     -15.448      -5.499\n",
      "age              -0.0421      0.313     -0.134      0.893      -0.656       0.572\n",
      "maritalstatus    -1.1720      0.623     -1.882      0.060      -2.392       0.048\n",
      "gender            0.4104      0.385      1.067      0.286      -0.344       1.164\n",
      "familyincome     -0.0953      0.307     -0.311      0.756      -0.696       0.506\n",
      "housepayment      0.2273      0.402      0.565      0.572      -0.561       1.016\n",
      "familysize        0.6899      0.472      1.461      0.144      -0.236       1.615\n",
      "V7               -0.8877      0.342     -2.592      0.010      -1.559      -0.217\n",
      "V8               -0.0391      0.170     -0.230      0.818      -0.372       0.294\n",
      "V9               -0.5473      0.471     -1.161      0.245      -1.471       0.376\n",
      "V10              -0.4851      0.386     -1.256      0.209      -1.242       0.272\n",
      "V11              -0.0100      0.448     -0.022      0.982      -0.887       0.867\n",
      "V12              -0.2720      0.639     -0.426      0.670      -1.524       0.980\n",
      "V13              -0.3919      0.555     -0.706      0.480      -1.479       0.695\n",
      "V14              -1.6724      0.513     -3.258      0.001      -2.678      -0.666\n",
      "V15              -0.0007      0.493     -0.001      0.999      -0.966       0.965\n",
      "V16              -0.1441      0.463     -0.311      0.756      -1.052       0.764\n",
      "V17               0.5323      0.378      1.410      0.159      -0.208       1.272\n",
      "V18               0.1795      0.551      0.326      0.745      -0.900       1.259\n",
      "V19               1.2134      0.558      2.176      0.030       0.120       2.306\n",
      "V20              -0.3539      0.532     -0.666      0.506      -1.396       0.688\n",
      "V21               0.2270      0.340      0.669      0.504      -0.438       0.892\n",
      "V22              -0.0931      0.672     -0.138      0.890      -1.410       1.224\n",
      "V23               0.3085      0.387      0.798      0.425      -0.449       1.066\n",
      "V24               1.1959      0.926      1.291      0.197      -0.620       3.011\n",
      "V25              -0.6079      0.807     -0.753      0.451      -2.189       0.974\n",
      "V26              -1.2924      1.324     -0.976      0.329      -3.888       1.303\n",
      "V27              -0.9713      0.780     -1.246      0.213      -2.500       0.557\n",
      "V28              -1.1024      1.241     -0.888      0.374      -3.535       1.330\n",
      "Amount            0.0035      0.002      2.100      0.036       0.000       0.007\n",
      "=================================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.66 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scripts.models import logistic_regression_model\n",
    "summary=logistic_regression_model(df4, target_column='Class', drop_columns=['id'], add_constant=True, return_type='Summary')\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numeric and Dummy Varibles dataseta (FD_02_apl_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of the processed data saved to: /Users/danramirez/mbs-fraud-detection/02-output/testmerge.csv\n"
     ]
    }
   ],
   "source": [
    "from scripts.dataclean import preprocess_for_lightgbm\n",
    "processed_data = preprocess_for_lightgbm(df5, 'SK_ID_CURR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model comparsions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Decision Tree Accuracy: 85.20%\n"
     ]
    }
   ],
   "source": [
    "from scripts.models import train_and_evaluate_decision_tree,train_and_evaluate_random_forest,train_and_evaluate_knn,train_and_evaluate_gaussian_nb\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "_= train_and_evaluate_decision_tree(processed_data, 'TARGET', [],test_size=0.3, random_state=42, return_accuracy_only=True, top_n_features=20)\n",
    "_= train_and_evaluate_random_forest(processed_data, 'TARGET', [], test_size=0.3, random_state=42, return_accuracy_only=True, top_n_features=20)\n",
    "_= train_and_evaluate_knn(processed_data, 'TARGET', [], n_neighbors=5, return_accuracy_only=True)\n",
    "_= train_and_evaluate_gaussian_nb(processed_data, 'TARGET', [], return_accuracy_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Details review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The `FD_02_apl_train` dataset underwent several model comparisons, showcasing diverse performance across various algorithms. Notably, Random Forest emerged as the leading model with an accuracy of 91.97%, closely followed by Gaussian Naive Bayes and KNN, both demonstrating high accuracy levels above 91%. This indicates a strong ability of these models to generalize well over the dataset.\n",
    "- The decision tree model displayed a comparatively lower accuracy of 85.20%. This divergence in performance may highlight the decision tree's sensitivity to the specific characteristics of the dataset, such as its feature distribution or the presence of complex, non-linear relationships that ensemble methods like Random Forest can better capture.\n",
    "- A deeper analysis into the classification reports reveals critical insights. For instance, the decision tree model's classification report illustrates its capacity to achieve high precision and recall for the majority class but faces challenges with the minority class. This pattern suggests a potential overfitting to the majority class or a need for more nuanced feature engineering to improve minority class predictions.\n",
    "- Random Forest's classification report exhibits high precision for the majority class but a total inability to predict the minority class correctly, as indicated by a recall of 0. This could point to the model's overemphasis on the majority class, likely due to class imbalance. It underscores the importance of employing techniques like class weight adjustment, oversampling, or undersampling to enhance the model's sensitivity towards the minority class.\n",
    "- The comparative analysis also underlines the significance of model evaluation beyond mere accuracy metrics. It highlights the need to consider a model's performance in terms of precision, recall, and the f1-score to ensure a balanced predictive capability across all classes, which is crucial for applications like fraud detection where the minority class (fraudulent transactions) is of particular interest.\n",
    "- These insights suggest that while Random Forest offers the highest accuracy for the `FD_02_apl_train` dataset, there remains room for improvement, especially in handling class imbalance and enhancing minority class prediction. Future efforts could explore more sophisticated ensemble techniques, advanced feature engineering, and fine-tuning of model parameters to achieve a more equitable performance across classes.\n",
    "\n",
    "These insights are critical for understanding the strengths and limitations of various models applied to the `FD_02_apl_train` dataset, guiding future modeling efforts towards achieving not only high accuracy but also balanced precision and recall across classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.models import logistic_regression_model,train_and_evaluate_decision_tree,train_and_evaluate_random_forest,train_and_evaluate_knn,train_and_evaluate_gaussian_nb\n",
    "\n",
    "train_and_evaluate_decision_tree(processed_data, target_column='TARGET', drop_columns=[], return_accuracy_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.models import logistic_regression_model,train_and_evaluate_decision_tree,train_and_evaluate_random_forest,train_and_evaluate_knn,train_and_evaluate_gaussian_nb\n",
    "train_and_evaluate_random_forest(processed_data, target_column='TARGET', drop_columns=[], return_accuracy_only=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN and gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate_knn(processed_data, 'TARGET', [], n_neighbors=5, return_accuracy_only=False)\n",
    "train_and_evaluate_gaussian_nb(processed_data, 'TARGET', [], return_accuracy_only=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fraudenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
