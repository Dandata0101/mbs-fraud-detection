{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scripts.csvtopaquet import csv_to_parquet_single_file\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "csv1_file_path = os.path.join(current_directory, '01-data', 'ex_fraud.csv')\n",
    "csv2_file_path = os.path.join(current_directory, '01-data', 'ex_fraud2.csv')\n",
    "csv3_file_path = os.path.join(current_directory, '01-data', 'ex1_Base.csv')\n",
    "csv4_file_path = os.path.join(current_directory, '01-data', 'FD_creditcard_data.csv')\n",
    "\n",
    "output_file_path1 = os.path.join(current_directory, '01-data', 'ex_fraud.parquet')\n",
    "output_file_path2 = os.path.join(current_directory, '01-data', 'ex_fraud2.parquet')\n",
    "output_file_path3 = os.path.join(current_directory, '01-data', 'ex1_Base.parquet')\n",
    "output_file_path4 = os.path.join(current_directory, '01-data', 'FD_creditcard_data.parquet')\n",
    "output_file_path5 = os.path.join(current_directory, '01-data', 'FD_creditcard_data.parquet')\n",
    "\n",
    "'''\n",
    "csv_to_parquet_single_file(csv_file_path=csv1_file_path, output_file_path=output_file_path1, chunksize=100000, sample_rows=None, drop_columns=None)\n",
    "csv_to_parquet_single_file(csv_file_path=csv2_file_path, output_file_path=output_file_path2, chunksize=100000, sample_rows=None, drop_columns=None)\n",
    "csv_to_parquet_single_file(csv_file_path=csv3_file_path, output_file_path=output_file_path3, chunksize=100000, sample_rows=None, drop_columns=None)\n",
    "csv_to_parquet_single_file(csv_file_path=csv4_file_path, output_file_path=output_file_path4, chunksize=100000, sample_rows=None, drop_columns=None)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "parquetFile1 = os.path.join(current_directory, '01-data', 'ex_fraud.parquet')\n",
    "parquetFile2 = os.path.join(current_directory, '01-data', 'ex_fraud2.parquet')\n",
    "parquetFile3 = os.path.join(current_directory, '01-data', 'ex1_Base.parquet')\n",
    "parquetFile4 = os.path.join(current_directory, '01-data', 'FD_creditcard_data.parquet')\n",
    "parquetFile5 = os.path.join(current_directory, '01-data', 'FD_02_apl_train.parquet')\n",
    "\n",
    "df1 = pd.read_parquet(parquetFile1)\n",
    "df2 = pd.read_parquet(parquetFile2)\n",
    "df3 = pd.read_parquet(parquetFile3)\n",
    "df4 = pd.read_parquet(parquetFile4)\n",
    "df5 = pd.read_parquet(parquetFile5)\n",
    "\n",
    "\n",
    "print('df1:', df1.dtypes)\n",
    "print('')\n",
    "print('df2:',df2.dtypes)\n",
    "print('')\n",
    "print('df3:',df3.dtypes)\n",
    "print('')\n",
    "print('df4:',df4.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import numpy as np  # Importing numpy\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming your DataFrame and target variable setup\n",
    "X = df4.drop(['Class','id'], axis=1)\n",
    "Y = df4['Class']\n",
    "\n",
    "# Adding a constant to the model (intercept)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the model\n",
    "model = sm.Logit(Y, X).fit()\n",
    "\n",
    "# Get model summary\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import shap\n",
    "\n",
    "# Assuming your DataFrame and target variable setup\n",
    "X = df4.drop(['Class','id'], axis=1)\n",
    "Y = df4['Class']\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Training a Decision Tree Classifier\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions and evaluating the model\n",
    "y_pred = dt_model.predict(X_test)\n",
    "accuracy1 = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy1 * 100:.2f}%\")\n",
    "\n",
    "# Functions for calculating and estimating entropy are assumed to be correctly implemented as per your initial snippet\n",
    "# average_entropy_at_depths = estimate_entropy_at_depths(dt_model, X_train, y_train)\n",
    "# for depth, entropy in average_entropy_at_depths.items():\n",
    "#     print(f\"Depth {depth}: Average Entropy = {entropy:.4f}\")\n",
    "\n",
    "# Decision Tree visualization (truncated to the first 3 levels for simplicity)\n",
    "plt.figure(figsize=(20,15))\n",
    "plot_tree(dt_model, filled=True, feature_names=X.columns, class_names=['0', '1'], max_depth=5, fontsize=10)\n",
    "plt.title(\"Decision Tree Visualization (First 3 Levels)\")\n",
    "plt.show()\n",
    "\n",
    "# Displaying the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Predicted 0', 'Predicted 1'], yticklabels=['Actual 0', 'Actual 1'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n",
    "\n",
    "# Printing the classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "\n",
    "# Displaying feature importances\n",
    "feature_importances = pd.DataFrame(dt_model.feature_importances_, index=X.columns, columns=[\"Importance\"]).sort_values(by=\"Importance\", ascending=False)\n",
    "print(feature_importances)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import plot_tree\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier  # Changed from DecisionTreeClassifier to RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train the Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(random_state=42, n_estimators=100)  # You can adjust n_estimators and other parameters as needed\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "single_tree = rf_model.estimators_[0]\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "# Plot the single decision tree\n",
    "plot_tree(single_tree, \n",
    "          feature_names=X.columns, \n",
    "          class_names=['Class 0', 'Class 1'],  # Adjust class names as necessary\n",
    "          filled=True, \n",
    "          rounded=True, \n",
    "          max_depth=10)  # Limiting tree depth for easier visualization; adjust as needed\n",
    "\n",
    "plt.title(\"Visualizing a Single Decision Tree from Random Forest\")\n",
    "plt.show()\n",
    "\n",
    "y_pred = rf_model.predict(X_test)\n",
    "accuracy2 = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy2 * 100:.2f}%\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Predicted 0', 'Predicted 1'], yticklabels=['Actual 0', 'Actual 1'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "\n",
    "# Feature Importances\n",
    "feature_importances = pd.DataFrame(rf_model.feature_importances_, index=X.columns, columns=[\"Importance\"]).sort_values(by=\"Importance\", ascending=False)\n",
    "print(feature_importances)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier  # Import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Assuming X and Y are already defined\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train the K-Nearest Neighbors Classifier\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)  # n_neighbors is a key parameter\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = knn_model.predict(X_test)\n",
    "\n",
    "# Model Accuracy\n",
    "accuracy3 = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy3 * 100:.2f}%\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Predicted 0', 'Predicted 1'], yticklabels=['Actual 0', 'Actual 1'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB  # Import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "# Assuming X and Y are already defined\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train the Gaussian Naive Bayes Classifier\n",
    "gnb_model = GaussianNB()\n",
    "gnb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = gnb_model.predict(X_test)\n",
    "\n",
    "# Model Accuracy\n",
    "accuracy4 = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy4 * 100:.2f}%\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Predicted 0', 'Predicted 1'], yticklabels=['Actual 0', 'Actual 1'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Model Accuracy(Descision Tree): {accuracy1 * 100:.2f}%\")\n",
    "print(f\"Model Accuracy(Random Forest): {accuracy2 * 100:.2f}%\")\n",
    "print(f\"Model Accuracy(KNN): {accuracy3 * 100:.2f}%\")\n",
    "print(f\"Model Accuracy(Gaussian): {accuracy4 * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df5 = df5.fillna(0)\n",
    "df5.columns = df5.columns.str.replace('[^a-zA-Z0-9_]', '_')\n",
    "df5.columns = df5.columns.str.replace('/', '_')\n",
    "\n",
    "\n",
    "print('train Data:')\n",
    "print(df5.dtypes)\n",
    "print('')\n",
    "\n",
    "train = df5\n",
    "\n",
    "current_data = pd.concat([train], axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Then proceed with training your LightGBM model\n",
    "dataset=current_data\n",
    "\n",
    "print('dataset:',dataset['TARGET'].dtypes)\n",
    "# Splitting the DataFrame into object and numeric DataFrames\n",
    "current_data_object = dataset.select_dtypes(include=['object'])\n",
    "Current_data_Numericonly = dataset.select_dtypes(include=['number'])  # This includes int, float, etc.\n",
    "current_data_object.columns.tolist()\n",
    "Current_data_Numericonly.columns.tolist()\n",
    "columns_data = dataset.columns.values.tolist()\n",
    "dummy_columns = pd.get_dummies(current_data_object, dtype=int)\n",
    "\n",
    "\n",
    "merged_data = pd.concat([Current_data_Numericonly, dummy_columns], axis=1)\n",
    "# Drop 'SK_ID_CURR' and columns with blank names\n",
    "merged_data.drop(columns=['SK_ID_CURR'], inplace=True)\n",
    "def clean_column_names(df):\n",
    "    df.columns = [col.replace('{', '')\n",
    "                     .replace('}', '')\n",
    "                     .replace('[', '')\n",
    "                     .replace(']', '')\n",
    "                     .replace('\"', '')\n",
    "                     .replace(':', '')\n",
    "                     .replace(',', '') for col in df.columns]\n",
    "    return df\n",
    "\n",
    "# Clean the column names of your DataFrame\n",
    "merged_data = clean_column_names(merged_data)\n",
    "\n",
    "print(merged_data.dtypes)\n",
    "\n",
    "sample=merged_data.head(1)\n",
    "print(merged_data.head(1).T)\n",
    "print('')\n",
    "print('Merged data:',merged_data.dtypes)\n",
    "sample.to_csv('testmerge.csv')\n",
    "\n",
    "print(Current_data_Numericonly.dtypes)\n",
    "\n",
    "# To see the columns of each DataFrame\n",
    "print(\"Object Columns:\", len(current_data_object.columns.tolist()))\n",
    "print(\"Numeric Columns:\", len(Current_data_Numericonly.columns.tolist()))\n",
    "\n",
    "columns_data[(columns_data == 'current_data')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import plot_tree\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import shap  # Make sure SHAP is installed\n",
    "\n",
    "# Assuming your DataFrame and target variable setup\n",
    "x = merged_data.drop('TARGET', axis=1)\n",
    "y = merged_data['TARGET']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train the Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(random_state=42, n_estimators=100, verbose=2)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "single_tree = rf_model.estimators_[0]\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plot_tree(single_tree, \n",
    "          feature_names=x.columns, \n",
    "          class_names=['Class 0', 'Class 1'],  # Adjust class names as necessary\n",
    "          filled=True, \n",
    "          rounded=True, \n",
    "          max_depth=10)  # Limiting tree depth for easier visualization; adjust as needed\n",
    "plt.title(\"Visualizing a Single Decision Tree from Random Forest\")\n",
    "plt.show()\n",
    "\n",
    "y_pred = rf_model.predict(X_test)\n",
    "accuracy2 = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy2 * 100:.2f}%\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Predicted 0', 'Predicted 1'], yticklabels=['Actual 0', 'Actual 1'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select top N features for readability\n",
    "top_n = 20\n",
    "sorted_idx = rf_model.feature_importances_.argsort()[-top_n:]\n",
    "\n",
    "plt.figure(figsize=(10, 8))  # Increase figure size\n",
    "plt.barh(x.columns[sorted_idx], rf_model.feature_importances_[sorted_idx], color='skyblue')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Top 20 Feature Importances')\n",
    "plt.tick_params(axis='y', which='major', labelsize=12)  # Increase label font size\n",
    "plt.tight_layout()  # Adjust layout to fit labels\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danramirez/mbs-fraud-detection/fraudenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2005\n",
      "           1       0.92      0.73      0.81        15\n",
      "\n",
      "    accuracy                           1.00      2020\n",
      "   macro avg       0.96      0.87      0.91      2020\n",
      "weighted avg       1.00      1.00      1.00      2020\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danramirez/mbs-fraud-detection/fraudenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2005\n",
      "           1       0.60      0.80      0.69        15\n",
      "\n",
      "    accuracy                           0.99      2020\n",
      "   macro avg       0.80      0.90      0.84      2020\n",
      "weighted avg       1.00      0.99      0.99      2020\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2005\n",
      "           1       0.85      0.73      0.79        15\n",
      "\n",
      "    accuracy                           1.00      2020\n",
      "   macro avg       0.92      0.87      0.89      2020\n",
      "weighted avg       1.00      1.00      1.00      2020\n",
      "\n",
      "r1_f1_score:0.91\n",
      "r2_f1_score:0.84\n",
      "r3_f1_score:0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danramirez/mbs-fraud-detection/fraudenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "df4\n",
    "# Assuming your DataFrame and target variable setup\n",
    "x4 = df4.drop('Class', axis=1)\n",
    "y4 = df4['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x4, y4, test_size=0.4, random_state=0)\n",
    "\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "predicted1 = lr.predict(X_test)\n",
    "\n",
    "#r1 = (classification_report(y_test, predicted1,output_dict=True))\n",
    "r1 = (classification_report(y_test, predicted1))\n",
    "print(r1)\n",
    "\n",
    "\n",
    "resampling = SMOTE()\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "\n",
    "pipeline = Pipeline([('SMOTE', resampling), ('Logistic Regression', lr)])\n",
    "pipeline.fit(X_train, y_train)\n",
    "predicted2 = pipeline.predict(X_test)\n",
    "\n",
    "r2 = print(classification_report(y_test, predicted2))\n",
    "\n",
    "resampling = BorderlineSMOTE(kind='borderline-1')\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "\n",
    "pipeline = Pipeline([('BSMOTE', resampling), ('Logistic Regression', lr)])\n",
    "pipeline.fit(X_train, y_train)\n",
    "predicted3 = pipeline.predict(X_test)\n",
    "\n",
    "r3 = (classification_report(y_test, predicted3))\n",
    "print(r3)\n",
    "\n",
    "###HOW TO ACCESS THE CLASSIFICATION REPORT SCORES\n",
    "r1_f1_score = round((classification_report(y_test, predicted1,output_dict=True))['macro avg']['f1-score'],2)\n",
    "r2_f1_score = round((classification_report(y_test, predicted2,output_dict=True))['macro avg']['f1-score'],2)\n",
    "r3_f1_score = round((classification_report(y_test, predicted3,output_dict=True))['macro avg']['f1-score'],2)\n",
    "\n",
    "print(f'r1_f1_score:{r1_f1_score}\\nr2_f1_score:{r2_f1_score}\\nr3_f1_score:{r3_f1_score}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fraudenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
